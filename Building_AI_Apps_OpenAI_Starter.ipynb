{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1uVrakdpb0CVRfsXAkE1TbuhHtiFNfCif",
      "authorship_tag": "ABX9TyNSl/TBXJh7i2IY69QBTGGT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nbeaudoin/Caltech-lecture-LLMs/blob/main/Building_AI_Apps_OpenAI_Starter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nick's standard preamble on the code**: The code for this section is a combination of this author's code, former notes, use of a Gen AI coding assistant, and snippets of product documentation and, where cited, from other tutorials of fantastic authors."
      ],
      "metadata": {
        "id": "6zRWmHTPcma4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making an API call to a LLM\n",
        "\n",
        "For starters, we will make an API call to OpenAI's GPT 3.5-turbo. GPT-4 is also on the market, but the cost is 20x more expensive and we don't have a need for having such a robust system.\n",
        "\n",
        "First you will need to make an account at OpenAI: https://openai.com/blog/openai-api\n",
        "\n",
        "Then you will need to create an AIP key: https://platform.openai.com/docs/overview\n",
        "\n",
        "Finally, you will need to store it"
      ],
      "metadata": {
        "id": "EdBxnm5kJcm1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First look at Open AI models\n",
        "\n",
        "https://platform.openai.com/docs/models/overview\n",
        "\n",
        "\n",
        "\n",
        "*  GPT base\n",
        "*  GPT-3 (training data cutoff: 2019)\n",
        "*  GPT 3.5 (training data cutoff: 2021)\n",
        "*  GPT 4 (training data cuff: 2023)\n",
        "\n"
      ],
      "metadata": {
        "id": "sAErQWGzYj7A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Token limits (context window)\n",
        "\n",
        "We keep seeing something called a `token limit`. What is this? this is the number of tokens (words really) that you can pass into the model at one time.\n",
        "\n",
        "* GPT-3 - ~4k\n",
        "* GPT 3.5 - ~32k\n",
        "* GPT 4 - 128k!!!!"
      ],
      "metadata": {
        "id": "S_ILi0pIZX07"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Storing passwords\n",
        "\n",
        "We don't want to store our API keys in our code sinc ewe will most likely be sharing that code. If you push your code to a repo, say on GitHub, your API key will be exposed. OpenAI has an API crawler that they deploy to look for API keys that are on GitHub and will send you an email saying that your access to that API has been removed. That is not the end of the world. But there are other times when you have compute capacity tied to an account where it becomes a very expensive mistake. Recall from the lecture the example of the AWS key that was set as a honeypot!\n",
        "\n",
        "Google Colab has a very straight forward method of storing AIP keys"
      ],
      "metadata": {
        "id": "uogDy6jBJw0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('openai_api_key')"
      ],
      "metadata": {
        "id": "5XOgVEHtJybd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4af09d4d-5549-4f76-8bbc-654ff78f475d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'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'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "id": "74ZqsB65eQLL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1831be9-2003-4275-8351-d7a854bdcded"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/226.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m225.3/226.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.3-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.3 httpx-0.26.0 openai-1.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set environment variable\n",
        "import os\n",
        "import openai\n",
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "JfotcI5IcR_T"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign your API key\n",
        "OPENAI_API_KEY = userdata.get('openai_api_key')\n",
        "#OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "SQTbmL03fVwG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling the API\n",
        "\n",
        "### Hello World"
      ],
      "metadata": {
        "id": "NvXp_BdhYRtn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WrzkYQRZdfo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### JSON format\n",
        "\n",
        "WOW! Out of the box that was pretty cool. So what did we do? We gave OpenAI's GPT-3.5-turbo model a prompt and then asked our question. The prompt here was key. Let's see what else OpenAI can do out of the box with a little customization. What happens if we need the output to be a JSON objcet because it needs to integrate with one of our applications?"
      ],
      "metadata": {
        "id": "oVOm4E65ggDc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eXziljQ0g4WP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Your turn\n",
        "Create a persona of your own and have fun with new questions!"
      ],
      "metadata": {
        "id": "J8WALT1p3FMO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6wXDkwmYJXCh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}